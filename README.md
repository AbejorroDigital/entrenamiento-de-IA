---

# Llama-3.2-1B-Espanol: Cr√≥nica de una Reeducaci√≥n Conceptual

[![Model on Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Model-ffd21e)](https://huggingface.co/CEGTEdicion/Llama-3.2-1B-espanol)
Este repositorio documenta el proceso de especializaci√≥n del modelo **Llama 3.2-1B**, transformando un modelo de par√°metros reducidos en un asistente acad√©mico capaz de disertar con precisi√≥n sobre ciencias biol√≥gicas y fotos√≠ntesis en un espa√±ol fluido y natural.

## üìù Filosof√≠a del Proyecto

En la era de los Grandes Modelos de Lenguaje (LLM), los modelos peque√±os suelen enfrentar el desaf√≠o de las **alucinaciones t√©cnicas** debido a su capacidad limitada de almacenamiento de hechos. Este proyecto nace de una premisa acad√©mica: *no se trata de cu√°ntos par√°metros tiene el modelo, sino de la calidad de la "dieta" informativa con la que se entrena*. Mediante la **Destilaci√≥n de Datos Sint√©ticos** y el uso de **LoRA**, refinamos el razonamiento del modelo sin sacrificar su agilidad.

---

## üõ†Ô∏è El Ciclo de Desarrollo (Arquitectura de Scripts)

El flujo de trabajo se ha dise√±ado como una secuencia l√≥gica de cuatro actos:

### 01. Preparaci√≥n del Laboratorio (`01_setup.sh`)

La base de cualquier investigaci√≥n de IA es un entorno predecible. Este script no solo instala dependencias, sino que garantiza que la comunicaci√≥n entre la GPU y **Unsloth** sea √≥ptima.

* **Recomendaci√≥n:** Siempre verifica que tu sesi√≥n tenga asignada una GPU (T4 o superior). El √©xito de este script depende de que las librer√≠as `xformers` y `bitsandbytes` se alineen correctamente con la arquitectura CUDA del sistema.

### 02. Neuroplasticidad Controlada (`02_load_model.py`)

Aqu√≠ cargamos la estructura cerebral del modelo. Aplicamos **cuantizaci√≥n de 4 bits** para que el modelo sea ligero, pero activamos los adaptadores LoRA en todos los m√≥dulos clave (`q, k, v, o, gate, up, down_proj`).

* **Recomendaci√≥n:** Al entrenar modelos de 1B para conceptos cient√≠ficos, es preferible usar un rango (`r`) de 16 o 32. Rangos menores pueden ser insuficientes para capturar la terminolog√≠a t√©cnica compleja.

### 03. El Proceso de Reeducaci√≥n (`03_train_model.py`)

El motor de aprendizaje. Este script es donde inyectamos el conocimiento corregido. El modelo aprende a sustituir sus errores previos por verdades cient√≠ficas.
Dataset recomendados para practicar como: bertin-project/alpaca-spanish, plncmm/spanish-alpaca, saillab/alpaca-spanish-cleaned

* **Recomendaci√≥n Cr√≠tica:** No satures el modelo con datos repetitivos. La clave es el **intercalado**: mezcla ensayos profundos generados por modelos mayores (Gemini) con preguntas cortas y precisas (Q&A). Esto evita que el modelo pierda su capacidad de s√≠ntesis mientras gana profundidad.

### 04. Inferencia y Sincronizaci√≥n del Conocimiento (`04_inference_and_export.py`)

El acto final donde validamos la "nueva conciencia" del modelo y la fusionamos en un archivo de 16 bits para su distribuci√≥n global.

* **Recomendaci√≥n:** Antes de la subida final a Hugging Face, realiza pruebas de "contraste". Hazle al modelo la misma pregunta que antes fallaba (ej: el uso del ox√≠geno). Si la respuesta es correcta y fluida, el modelo est√° listo para el mundo.

---

## üîê Seguridad y Gobernanza de Datos

La integridad de tu repositorio oficial `CEGTEdicion/Llama-3.2-1B-espanol` depende de una gesti√≥n de credenciales impecable.

* **Token de Acceso:** Utiliza siempre un token con permisos de **Escritura (Write)**.
* **Documentaci√≥n de Secretos:** Nunca escribas tu API Key directamente en el c√≥digo; utiliza el sistema de secretos de tu entorno (Colab Secrets o variables de entorno) para mantener tu "llave maestra" protegida.

---

## üöÄ Hoja de Ruta para el Usuario

1. **Clonaci√≥n:** Trae el c√≥digo a tu entorno local.
2. **Suministro de Datos:** Coloca tu archivo `tu_dataset.json` en la ra√≠z. Aseg√∫rate de que siga el formato Alpaca: `{"instruction": "...", "output": "..."}`.
3. **Ejecuci√≥n:** Sigue el orden num√©rico de los scripts. Si cambias la l√≥gica en el Script 03, recuerda que el Script 04 heredar√° esos cambios en la inferencia.

---

**Autor:** CEGTEdicion

**Visi√≥n:** Democratizar la inteligencia artificial de alta precisi√≥n, demostrando que el tama√±o del modelo no es un l√≠mite para la excelencia acad√©mica.

---
